services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zk-data:/var/lib/zookeeper/data
      - zk-txn-logs:/var/lib/zookeeper/log
    networks:
      - real-estate-network

  # Kafka Broker
  broker:
    container_name: broker
    image: confluentinc/cp-kafka:7.4.10
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - real-estate-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: schema-registry
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8082:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - real-estate-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # PostgreSQL for storing features and reference data
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_DB: real_estate
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    networks:
      - real-estate-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d real_estate"]
      interval: 30s
      timeout: 10s
      retries: 5
      
  kafka-connect:
    image: debezium/connect:2.3.4.Final
    container_name: kafka-connect
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: broker:29092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-status
      
      # Key and Value Converters
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8082
      VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8082
      
      # Internal Key and Value Converters
      INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      
      # REST API Configuration
      REST_ADVERTISED_HOST_NAME: kafka-connect
      REST_PORT: 8083
      
      # Plugin Path
      PLUGIN_PATH: /kafka/connect
      
      # Connect Configuration
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      
      # Fixed Logging Configuration
      # CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      # CONNECT_LOG4J_APPENDER_STDOUT: org.apache.log4j.ConsoleAppender
      # CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT: org.apache.log4j.PatternLayout
      # CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      
      # Heap Settings

      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"

    networks:
      - real-estate-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/connectors || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./debezium-config.json:/tmp/debezium-config.json
      - ./log4j.properties:/kafka/config/log4j.properties

  # Debezium UI (optional, for easier management)
  debezium-ui:
    image: debezium/debezium-ui:2.4
    container_name: debezium-ui
    depends_on:
      kafka-connect:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CONNECT_URIS: http://kafka-connect:8083
    networks:
      - real-estate-network

  # Kafka Topic Creator - Separate service to create topics
  kafka-setup:
    image: confluentinc/cp-kafka:7.4.10
    container_name: kafka-setup
    depends_on:
      broker:
        condition: service_healthy
    networks:
      - real-estate-network
    command: >
      sh -c "
        echo 'Waiting for Kafka to be ready...' &&
        sleep 30 &&
        echo 'Creating Kafka topics...' &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic property-listings --partitions 1 --replication-factor 1 &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic price-changes --partitions 1 --replication-factor 1 &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic property-interactions --partitions 1 --replication-factor 1 &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic market-events --partitions 1 --replication-factor 1 &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic connect-configs --partitions 1 --replication-factor 1 --config cleanup.policy=compact &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic connect-offsets --partitions 25 --replication-factor 1 --config cleanup.policy=compact &&
        kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic connect-status --partitions 5 --replication-factor 1 --config cleanup.policy=compact &&
        echo 'Listing created topics:' &&
        kafka-topics --bootstrap-server broker:29092 --list &&
        echo 'Topics setup completed successfully'
      "
    restart: "no"

  # Service to setup Debezium connector - FIXED VERSION
  debezium-setup:
    image: confluentinc/cp-kafka:7.4.10
    container_name: debezium-setup
    depends_on:
      kafka-connect:
        condition: service_healthy
      kafka-setup:
        condition: service_completed_successfully
    networks:
      - real-estate-network
    volumes:
      - ./debezium-config.json:/tmp/debezium-config.json
    command: >
      sh -c "
        echo 'Waiting for Kafka Connect to be ready...' &&
        sleep 30 &&
        echo 'Setting up Debezium PostgreSQL connector...' &&
        curl -X POST http://kafka-connect:8083/connectors \
          -H 'Content-Type: application/json' \
          -d @/tmp/debezium-config.json &&
        echo 'Debezium connector setup completed'
      "
    restart: "no"

  # Redis for real-time feature serving
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - real-estate-network

  # Flink JobManager
  jobmanager:
    container_name: jobmanager
    image: flink:1.18-scala_2.12-java17
    ports:
      - "8081:8081"  
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        jobmanager.bind-host: 0.0.0.0
        rest.address: 0.0.0.0
        rest.bind-address: 0.0.0.0
        rest.port: 8081
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 1
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        state.savepoints.dir: file:///tmp/flink-savepoints
        jobmanager.memory.process.size: 2048m
        restart-strategy: fixed-delay
        restart-strategy.fixed-delay.attempts: 5
        restart-strategy.fixed-delay.delay: 30s
        slot.sharing.enabled: true
        cluster.evenly-spread-out-slots: true
        slot.request.timeout: 300000
        slot.idle.timeout: 300000
    volumes:
      - flink-checkpoints:/tmp/flink-checkpoints
      - flink-savepoints:/tmp/flink-savepoints
      - ./flink-jobs:/opt/flink/jobs
      - ./gcp-credentials.json:/opt/flink/gcp-credentials.json
      - ./beam-runners-flink-1.18-2.57.0.jar:/opt/flink/lib/beam-runners-flink-1.18-2.57.0.jar
      - ./beam-sdks-java-core-2.57.0.jar:/opt/flink/lib/beam-sdks-java-core-2.57.0.jar
    networks:
      - real-estate-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Flink TaskManager
  taskmanager:
    image: flink:1.18-scala_2.12-java17
    depends_on:
      jobmanager:
        condition: service_healthy
    command: taskmanager
    scale: 2
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.bind-host: 0.0.0.0
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 1
        taskmanager.memory.process.size: 2048m
      - GOOGLE_APPLICATION_CREDENTIALS=/opt/flink/gcp-credentials.json
    volumes:
      - flink-checkpoints:/tmp/flink-checkpoints
      - flink-savepoints:/tmp/flink-savepoints
      - ./gcp-credentials.json:/opt/flink/gcp-credentials.json
      - ./beam-runners-flink-1.18-2.57.0.jar:/opt/flink/lib/beam-runners-flink-1.18-2.57.0.jar
      - ./beam-sdks-java-core-2.57.0.jar:/opt/flink/lib/beam-sdks-java-core-2.57.0.jar
    networks:
      - real-estate-network

  # Data Generator Service
  data-generator:
    build:
      context: ./data-generator
      dockerfile: Dockerfile
    container_name: data-generator
    depends_on:
      broker:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:29092
      POSTGRES_HOST: postgres
      POSTGRES_DB: real_estate
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./data-generator:/app
    networks:
      - real-estate-network

  # Job Submitter - Simplified version
  job-submitter:
    build:
      context: ./flink-job-submitter
    container_name: job-submitter
    depends_on:
      jobmanager:
        condition: service_healthy
      taskmanager:
        condition: service_started
      kafka-setup:
        condition: service_completed_successfully
    environment:
      - FLINK_JOBMANAGER_HOST=jobmanager
      - FLINK_JOBMANAGER_PORT=8081
      - FLINK_JOBMANAGER_URL=http://jobmanager:8081
    volumes:
      - ./target:/jobs
      - ./logs:/opt/flink/log 
      - ./beam-sdks-java-core-2.57.0.jar:/opt/flink/lib/beam-sdks-java-core-2.57.0.jar
      - ./beam-sdks-java-io-kafka-2.57.0.jar:/opt/flink/lib/beam-sdks-java-io-kafka-2.57.0.jar
      - ./beam-runners-flink-1.18-2.57.0.jar:/opt/flink/lib/beam-runners-flink-1.18-2.57.0.jar
    networks:
      - real-estate-network
    command: |
        sh -c "
          echo 'Waiting for JobManager to be fully ready...' &&
          sleep 5 &&
          echo 'Starting job submission...' &&
          /opt/flink/bin/flink run -c com.example.beam.FlinkPropertyListingPipeline -d /jobs/property-listing-pipeline-bundled-1.0-SNAPSHOT.jar "
    restart: "no"

volumes:
  zk-data:
  zk-txn-logs:
  kafka-data:
  postgres-data:
  redis-data:
  flink-checkpoints:
  flink-savepoints:
  grafana-data:
  prometheus-data:

networks:
  real-estate-network:
    driver: bridge